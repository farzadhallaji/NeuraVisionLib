{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/NeuraVisionLib/')\n",
    "## ! git reset --hard\n",
    "# ! git pull\n",
    "\n",
    "while not 'dataloaders' in os.listdir():\n",
    "    os.chdir('../')\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('../../../MyDrive/mass_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install rasterio > install.txt\n",
    "! rm -rf install.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "while not 'dataloaders' in os.listdir():\n",
    "    os.chdir('../')\n",
    "\n",
    "from rasterio.errors import NotGeoreferencedWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=NotGeoreferencedWarning)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "from dataloaders.mass_roads_dataloader import (\n",
    "    MassRoadsDataset, custom_collate_fn\n",
    ")\n",
    "from models.MULDE.models import MLPs, ScoreOrLogDensityNetwork\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Noise Levels: [0.         0.05       0.08035714 0.11071429 0.14107142 0.17142856\n",
      " 0.20178571 0.23214285 0.2625     0.29285714 0.32321426 0.35357141\n",
      " 0.38392854 0.4142857  0.44464284 0.475      0.50535715 0.53571427\n",
      " 0.56607145 0.5964286  0.6267857  0.6571429  0.6875     0.7178571\n",
      " 0.74821424 0.7785714  0.80892855 0.8392857  0.86964285 0.9       ]\n",
      "Total patches available: 145200\n",
      "Total patches available: 968\n",
      "Total patches available: 968\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Hyperparameters ---\n",
    "DATA_DIR = '/home/ri/Desktop/Projects/Datasets/Mass_Roads/dataset/'\n",
    "CHECKPOINT_PATH = 'checkpoints/RoadSegMulde/log_density_segmentation_checkpoint.pth'\n",
    "BEST_MODEL_PATH = 'checkpoints/RoadSegMulde/best_log_density_segmentation_model.pth'\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "WEIGHT_DECAY = 1e-5\n",
    "ACCUMULATION_STEPS = 4  # Reduce accumulation steps\n",
    "BATCH_SIZE = 8  # Reduce batch size to stabilize gradients\n",
    "\n",
    "# Enable gradient clipping\n",
    "MAX_GRAD_NORM = 1.0  # Clip gradients to prevent explosions\n",
    "\n",
    "EPOCHS = 300\n",
    "WINDOW_SIZE = 128\n",
    "WINDOW_STRIDE = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SIGMA_MIN = 0.05\n",
    "SIGMA_MAX = 0.9\n",
    "NUM_NOISE_LEVELS = 30\n",
    "USE_AUTOMATIC_MIXED_PRECISION = True\n",
    "LOAD_FROM = None #'last' # best or None\n",
    "LOAD_FROM = 'last' # best or None\n",
    "# DEBUG = True\n",
    "DEBUG = False\n",
    "\n",
    "arithmetic_noise = torch.linspace(SIGMA_MIN, SIGMA_MAX, steps=NUM_NOISE_LEVELS - 1).to(DEVICE)\n",
    "noise_levels = torch.cat([torch.tensor([0.0], device=DEVICE), arithmetic_noise])\n",
    "print(\"Generated Noise Levels:\", noise_levels.cpu().numpy())\n",
    "\n",
    "# --- Dataset Preparation ---\n",
    "train_dataset = MassRoadsDataset(root_dir=DATA_DIR, split='train', window_size=WINDOW_SIZE, stride=WINDOW_STRIDE)#, max_images=300)\n",
    "val_dataset = MassRoadsDataset(root_dir=DATA_DIR, split='valid', window_size=WINDOW_SIZE, stride=WINDOW_STRIDE)#, max_images=2)\n",
    "test_dataset = MassRoadsDataset(root_dir=DATA_DIR, split='test', window_size=WINDOW_SIZE, stride=WINDOW_STRIDE)#, max_images=2)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patches_and_distribution_with_counts(sat_patches, map_patches, metadata, n_patches=3):\n",
    "    \"\"\"\n",
    "    Efficiently plots randomly selected satellite patches, road masks, and road pixel distributions.\n",
    "    \n",
    "    Args:\n",
    "        sat_patches (Tensor): Batch of satellite image patches.\n",
    "        map_patches (Tensor): Batch of road mask patches.\n",
    "        metadata (List[Tuple[int, int, int]]): Metadata with (image_idx, y, x).\n",
    "        n_patches (int): Number of patches to visualize.\n",
    "    \"\"\"\n",
    "    n_patches = min(n_patches, sat_patches.shape[0])  # Ensure we do not exceed available patches\n",
    "\n",
    "    # Randomly select `n_patches` indices from the batch\n",
    "    selected_indices = random.sample(range(sat_patches.shape[0]), n_patches)\n",
    "\n",
    "    fig, axes = plt.subplots(n_patches, 3, figsize=(15, 5 * n_patches))\n",
    "\n",
    "    # Ensure axes is always iterable\n",
    "    if n_patches == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        sat_patch = sat_patches[idx]\n",
    "        map_patch = map_patches[idx]\n",
    "\n",
    "        # Convert tensors to numpy\n",
    "        if isinstance(sat_patch, torch.Tensor):\n",
    "            sat_patch = sat_patch.cpu().numpy().transpose(1, 2, 0)  # Convert to HxWxC\n",
    "        if isinstance(map_patch, torch.Tensor):\n",
    "            map_patch = map_patch.cpu().numpy()\n",
    "\n",
    "        # Extract metadata (fix KeyError)\n",
    "        image_idx, y, x = metadata[idx]  \n",
    "\n",
    "        # Plot Satellite Patch\n",
    "        axes[i][0].imshow(sat_patch)\n",
    "        axes[i][0].set_title(f\"Satellite Patch {i+1}\\nImage Index: {image_idx}, Coords: ({y}, {x})\")\n",
    "        axes[i][0].axis('off')\n",
    "\n",
    "        # Plot Map Patch\n",
    "        axes[i][1].imshow(map_patch, cmap='gray')\n",
    "        axes[i][1].set_title(f\"Map Patch {i+1}\")\n",
    "        axes[i][1].axis('off')\n",
    "\n",
    "        # Plot Distribution of Road Pixels\n",
    "        road_pixel_count = np.sum(map_patch)\n",
    "        non_road_pixel_count = map_patch.size - road_pixel_count\n",
    "        labels = ['Non-Road', 'Road']\n",
    "        sizes = [non_road_pixel_count, road_pixel_count]\n",
    "\n",
    "        axes[i][2].pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=['gray', 'blue'])\n",
    "        axes[i][2].set_title(f\"Road Pixel Distribution (Patch {i+1})\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Count total batches in the dataset\n",
    "total_batches = len(train_loader)\n",
    "\n",
    "print(f\"Total Batches in Dataset: {total_batches}\\n\")\n",
    "\n",
    "# Iterate through the DataLoader and print batch sizes\n",
    "for batch_idx, (sat_patches, map_patches, metadata) in enumerate(train_loader):\n",
    "    if sat_patches is None or map_patches is None:\n",
    "        print(f\"Batch {batch_idx+1}: Skipped (Empty Batch)\")\n",
    "        continue  # Skip empty batches\n",
    "\n",
    "    # Print batch info\n",
    "    print(f\"\\nBatch {batch_idx+1}/{total_batches}:\")\n",
    "    print(f\"  Requested Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"  Actual Batch Size: {sat_patches.shape[0]}\")  # The number of patches in this batch\n",
    "    print(f\"  Patch Shape: {sat_patches.shape}\")  # (batch_size, channels, height, width)\n",
    "\n",
    "    if batch_idx >= 3:  # Stop printing after a few batches to avoid excessive output\n",
    "        break\n",
    "\n",
    "\n",
    "# --- Efficiently Load ONE Batch ---\n",
    "try:\n",
    "    batch = next(iter(train_loader))  # Load one batch\n",
    "    sat_patches, map_patches, metadata = batch\n",
    "\n",
    "    if sat_patches is not None and len(sat_patches) > 0:\n",
    "        plot_patches_and_distribution_with_counts(sat_patches, map_patches, metadata, n_patches=3)  # Show 3 patches\n",
    "    else:\n",
    "        print(\"No valid patches found in the batch.\")\n",
    "\n",
    "except StopIteration:\n",
    "    print(\"No data available in train_loader.\")\n",
    "\n",
    "\n",
    "noise_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_satellite_patch_with_noise(satellite_patch, noise_levels, n_samples=None):\n",
    "    \"\"\"\n",
    "    Plots the original satellite image patch alongside multiple noisy versions.\n",
    "\n",
    "    Args:\n",
    "        satellite_patch (Tensor): Single satellite image patch (C, H, W).\n",
    "        noise_levels (Tensor): Tensor of noise levels to apply.\n",
    "        n_samples (int): Number of noisy samples to generate (default: all).\n",
    "    \"\"\"\n",
    "    if n_samples is None:\n",
    "        n_samples = len(noise_levels)  # Use all noise levels\n",
    "\n",
    "    # Convert tensor to numpy for visualization\n",
    "    if isinstance(satellite_patch, torch.Tensor):\n",
    "        satellite_patch = satellite_patch.cpu().numpy()\n",
    "\n",
    "    # Ensure shape is (H, W, C)\n",
    "    if satellite_patch.shape[0] in [1, 3]:  # If (C, H, W), convert to (H, W, C)\n",
    "        satellite_patch = np.transpose(satellite_patch, (1, 2, 0))\n",
    "\n",
    "    # Normalize to [0,1] for proper visualization\n",
    "    satellite_patch = (satellite_patch - satellite_patch.min()) / (satellite_patch.max() - satellite_patch.min())\n",
    "\n",
    "    # Select `n_samples` evenly spaced noise levels\n",
    "    noise_indices = np.linspace(0, len(noise_levels) - 1, n_samples, dtype=int)\n",
    "    selected_noise_levels = noise_levels[noise_indices].cpu().numpy()\n",
    "\n",
    "    fig, axes = plt.subplots(1, n_samples + 1, figsize=(100, 5))\n",
    "\n",
    "    # Plot the original image\n",
    "    axes[0].imshow(satellite_patch)\n",
    "    axes[0].set_title(\"Original Patch\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Generate and apply noise\n",
    "    for i, noise_level in enumerate(selected_noise_levels):\n",
    "        noise = np.random.randn(*satellite_patch.shape) * noise_level  # Generate Gaussian noise\n",
    "        noisy_patch = np.clip(satellite_patch + noise, 0, 1)  # Add noise and clip values to [0,1]\n",
    "\n",
    "        axes[i + 1].imshow(noisy_patch)\n",
    "        axes[i + 1].set_title(f\"Noise: {noise_level:.3f}\")\n",
    "        axes[i + 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Test with real data from your DataLoader\n",
    "for batch_idx, (sat_patches, map_patches, _) in enumerate(train_loader):\n",
    "    if sat_patches is None or sat_patches.shape[0] == 0:\n",
    "        print(f\"Batch {batch_idx+1}: Skipped (Empty Batch)\")\n",
    "        continue  # Skip empty batches\n",
    "\n",
    "    print(f\"\\nBatch {batch_idx+1}:\")\n",
    "    print(f\"  Satellite Patch Shape: {sat_patches.shape}\")  # Debugging step\n",
    "    print(f\"  Selected Noise Levels: {noise_levels.cpu().numpy()}\")  # Debugging step\n",
    "\n",
    "    plot_satellite_patch_with_noise(sat_patches[0], noise_levels)  # Use the first patch in the batch\n",
    "\n",
    "    if batch_idx > 1:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Definition ---\n",
    "resnet = resnet50(pretrained=True)\n",
    "resnet = nn.Sequential(\n",
    "    *list(resnet.children())[:-2],\n",
    "    nn.AdaptiveAvgPool2d((1, 1))\n",
    ").to(DEVICE)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "    param.grad = None  # Ensure no gradients are tracked\n",
    "\n",
    "mlp = MLPs(\n",
    "    input_dim=2048 + 1,\n",
    "    output_dim=WINDOW_SIZE * WINDOW_SIZE,\n",
    "    units=[4096, 4096],\n",
    "    layernorm=True,\n",
    "    dropout=0.1\n",
    ")\n",
    "log_density_model = ScoreOrLogDensityNetwork(mlp, score_network=False).to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(log_density_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scaler = torch.amp.GradScaler() if USE_AUTOMATIC_MIXED_PRECISION else None\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "\n",
    "def calculate_metrics(predictions, targets, threshold=0.5):\n",
    "    preds = (predictions > threshold).float().cpu().numpy().astype(np.uint8).flatten()\n",
    "    targets = (targets > 0.5).float().cpu().numpy().astype(np.uint8).flatten()  # Ensure targets are binary\n",
    "    precision = precision_score(targets, preds, zero_division=1)\n",
    "    recall = recall_score(targets, preds, zero_division=1)\n",
    "    f1 = f1_score(targets, preds, zero_division=1)\n",
    "    iou = jaccard_score(targets, preds, zero_division=1)\n",
    "\n",
    "    return precision, recall, f1, iou\n",
    "\n",
    "# --- Save and Load Model ---\n",
    "def save_model(log_density_model, optimizer, epoch, loss, path):\n",
    "    directory = os.path.dirname(path)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': log_density_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, path)\n",
    "    print(f\"Model saved at {path}\")\n",
    "\n",
    "def load_checkpoint(path):\n",
    "    if os.path.exists(path):\n",
    "        checkpoint = torch.load(path, weights_only=True)\n",
    "        log_density_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        return checkpoint['epoch'], checkpoint['loss']\n",
    "    return 0, None\n",
    "\n",
    "\n",
    "# --- Loss Functions ---\n",
    "def hybrid_loss(pred, target, alpha=0.5, beta=0.4, gamma=0.01, use_bce=False, smooth=1e-6, debug=DEBUG):\n",
    "    \"\"\"\n",
    "    Hybrid loss function combining:\n",
    "    - BCE or MSE for pixel-wise similarity\n",
    "    - Dice Loss for segmentation\n",
    "    - KL Divergence for distribution learning\n",
    "    \"\"\"\n",
    "    pred_prob = torch.sigmoid(pred)  # Convert logits to probabilities\n",
    "\n",
    "    if debug:\n",
    "        print(f\"\\n[DEBUG] Hybrid Loss Calculation\")\n",
    "        print(f\"Pred Shape: {pred.shape}, Min: {pred.min().item()}, Max: {pred.max().item()}\")\n",
    "        print(f\"Target Shape: {target.shape}, Min: {target.min().item()}, Max: {target.max().item()}\")\n",
    "\n",
    "    # --- Pixel-wise Loss (BCE or MSE) ---\n",
    "    if use_bce:\n",
    "        pixel_loss = nn.BCEWithLogitsLoss()(pred, target)  # Uses raw logits\n",
    "    else:\n",
    "        pixel_loss = nn.MSELoss()(pred_prob, target)  # Uses probabilities\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Pixel Loss: {pixel_loss.item()}\")\n",
    "\n",
    "    # --- Dice Loss ---\n",
    "    intersection = (pred_prob * target).sum(dim=(1, 2, 3))\n",
    "    union = pred_prob.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3))\n",
    "    dice = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice = dice.mean()  # Keep batch dimension\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Dice Loss: {dice.item()} | Intersection: {intersection.mean().item()} | Union: {union.mean().item()}\")\n",
    "\n",
    "    # --- KL Divergence Loss ---\n",
    "    eps = 1e-6  # Prevent log(0)\n",
    "    target_sum = target.sum(dim=(1, 2, 3), keepdim=True) + eps\n",
    "    pred_sum = pred_prob.sum(dim=(1, 2, 3), keepdim=True) + eps\n",
    "    target_dist = (target + eps) / target_sum\n",
    "    pred_dist = (pred_prob + eps) / pred_sum\n",
    "    kl_div = F.kl_div(pred_dist.log(), target_dist, reduction=\"batchmean\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"KL Divergence Loss: {kl_div.item()} | Target Sum: {target_sum.mean().item()} | Pred Sum: {pred_sum.mean().item()}\")\n",
    "\n",
    "    # --- Compute Per-Patch Hybrid Loss ---\n",
    "    batch_size = pred.shape[0]  # Number of patches in the batch\n",
    "    loss = (alpha * pixel_loss + beta * dice + gamma * kl_div) / batch_size  # Normalize by batch size\n",
    "\n",
    "    if debug:\n",
    "        print(f\"[Loss] Pixel: {pixel_loss.item():.4f}, Dice: {dice.item():.4f}, KL: {kl_div.item():.4f}, Total: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Total Loss: {loss.item()}\")\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "# --- Forward Pass ---\n",
    "def forward_pass(satellite_patches, noise_levels, resnet, log_density_model, debug=DEBUG):\n",
    "    resnet.eval()\n",
    "    batch_size = satellite_patches.size(0)\n",
    "    num_noise_levels = len(noise_levels)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"\\n[Forward Pass] Batch Size: {batch_size}, Noise Levels: {num_noise_levels}\")\n",
    "        print(f\"Input Satellite Patches Shape: {satellite_patches.shape}\")\n",
    "\n",
    "    # Expand satellite patches for each noise level\n",
    "    satellite_patches = satellite_patches.repeat_interleave(num_noise_levels, dim=0)\n",
    "\n",
    "    # Expand noise levels dynamically\n",
    "    noise_tensor = noise_levels.view(1, -1, 1, 1).repeat(batch_size, 1, WINDOW_SIZE, WINDOW_SIZE).view(-1, 1, WINDOW_SIZE, WINDOW_SIZE)\n",
    "\n",
    "    if noise_tensor.shape[0] != satellite_patches.shape[0]:\n",
    "        print(f\"[ERROR] Noise Shape Mismatch! Expected {satellite_patches.shape[0]}, got {noise_tensor.shape[0]}\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Expanded Satellite Patches Shape: {satellite_patches.shape}\")\n",
    "        print(f\"Noise Tensor Shape: {noise_tensor.shape}\")\n",
    "\n",
    "    # Add noise\n",
    "    noisy_patches = satellite_patches + torch.randn_like(satellite_patches) * noise_tensor\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Noisy Patches Shape: {noisy_patches.shape}\")\n",
    "\n",
    "    # Extract features using frozen ResNet\n",
    "    features = resnet(noisy_patches).flatten(start_dim=1)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Extracted Features Shape: {features.shape}\")\n",
    "\n",
    "    # Add noise level information to features\n",
    "    noise_tensor_flat = noise_levels.repeat(batch_size, 1).view(-1, 1)\n",
    "    features_with_noise = torch.cat([features, noise_tensor_flat], dim=1)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Features with Noise Shape: {features_with_noise.shape}\")\n",
    "\n",
    "    # Pass through the log density model\n",
    "    predictions = log_density_model(features_with_noise)\n",
    "    predictions = torch.clamp(predictions, min=-10, max=10)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Raw Predictions Shape: {predictions.shape}\")\n",
    "\n",
    "    # Reshape final predictions correctly\n",
    "    final_predictions = predictions.view(batch_size, num_noise_levels, 1, WINDOW_SIZE, WINDOW_SIZE)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Final Predictions Shape: {final_predictions.shape}\")\n",
    "        print(f\"Final loss Predictions Shape: {final_predictions[:, 0, :, :, :].shape}\")\n",
    "        \n",
    "\n",
    "    return final_predictions\n",
    "\n",
    "\n",
    "\n",
    "# --- Training Function ---\n",
    "def train_one_epoch(train_loader, resnet, log_density_model, noise_levels, optimizer, device, scaler, accumulation_steps):\n",
    "    resnet.eval()\n",
    "    log_density_model.train()\n",
    "    \n",
    "    total_loss = 0  \n",
    "    total_patches = 0  \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_idx, (satellite_patches, road_maps, _) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        if satellite_patches is None or road_maps is None:\n",
    "            continue\n",
    "        \n",
    "        satellite_patches, road_maps = satellite_patches.to(device), road_maps.to(device).float().unsqueeze(1)\n",
    "        \n",
    "        with torch.autocast(device_type='cuda'):\n",
    "            predictions = forward_pass(satellite_patches, noise_levels, resnet, log_density_model)[:, 0, :, :, :]\n",
    "            loss = hybrid_loss(predictions, road_maps)  # Already per patch\n",
    "        \n",
    "        if torch.isnan(loss).any():\n",
    "            print(\"[ERROR] NaN detected in loss, stopping training.\")\n",
    "            return float('inf')\n",
    "        \n",
    "        # Ensure ResNet remains frozen\n",
    "        for name, param in resnet.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                print(f\"[ERROR] ResNet parameter {name} has gradients! It should be frozen.\")\n",
    "\n",
    "        # Backpropagation (handling accumulation)\n",
    "        scaler.scale(loss / accumulation_steps).backward()\n",
    "        \n",
    "        if DEBUG:\n",
    "            for name, param in log_density_model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    print(f\"{name} - Grad Norm: {param.grad.norm().item()}\")\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(log_density_model.parameters(), max_norm=MAX_GRAD_NORM)\n",
    "\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Accumulate per-patch loss correctly\n",
    "        total_loss += loss.item()  \n",
    "        total_patches += 1  \n",
    "    \n",
    "    return total_loss / total_patches if total_patches > 0 else float('inf')\n",
    "\n",
    "\n",
    "def validate_one_epoch(val_loader, resnet, log_density_model, noise_levels, device):\n",
    "    resnet.eval()\n",
    "    log_density_model.eval()\n",
    "    total_loss, total_patches = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for satellite_patches, road_maps, _ in tqdm(val_loader, desc=\"Validation\"):\n",
    "            if satellite_patches is None or road_maps is None:\n",
    "                continue\n",
    "            satellite_patches, road_maps = satellite_patches.to(device), road_maps.to(device).float().unsqueeze(1)\n",
    "            predictions = forward_pass(satellite_patches, noise_levels, resnet, log_density_model)[:, 0, :, :, :]\n",
    "            loss = hybrid_loss(predictions, road_maps)\n",
    "            total_loss += loss.item() * satellite_patches.size(0)\n",
    "            total_patches += satellite_patches.size(0)\n",
    "    return total_loss / total_patches\n",
    "\n",
    "\n",
    "\n",
    "# --- Main Training Loop ---\n",
    "def train_model(resnet, log_density_model, train_loader, val_loader, noise_levels, optimizer, scheduler, device, epochs, accumulation_steps, checkpoint_path, best_model_path, load_from='last'):\n",
    "    best_val_loss = float('inf')\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Load checkpoint if available\n",
    "    if load_from == \"last\" and os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading last checkpoint from {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "        log_density_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        last_loss = checkpoint['loss']\n",
    "        print(f\"Resumed training from epoch {start_epoch} with last loss: {last_loss:.4f}\")\n",
    "    elif load_from == \"best\" and os.path.exists(best_model_path):\n",
    "        print(f\"Loading best model from {best_model_path}\")\n",
    "        best_model_checkpoint = torch.load(best_model_path, weights_only=False)\n",
    "        log_density_model.load_state_dict(best_model_checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(best_model_checkpoint['optimizer_state_dict'])\n",
    "        best_val_loss = best_model_checkpoint['loss']\n",
    "        print(f\"Best model loaded with validation loss: {best_val_loss:.4f}\")\n",
    "    else:\n",
    "        print(\"Starting training from scratch.\")\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        train_loss = train_one_epoch(train_loader, resnet, log_density_model, noise_levels, optimizer, device, scaler, accumulation_steps)\n",
    "        val_loss = validate_one_epoch(val_loader, resnet, log_density_model, noise_levels, device)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        save_model(log_density_model, optimizer, epoch, val_loss, checkpoint_path)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(log_density_model, optimizer, epoch, best_val_loss, best_model_path)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18150/18150 [55:04<00:00,  5.49it/s] \n",
      "Validation: 100%|██████████| 121/121 [00:29<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.1836, Val Loss: 0.0764\n",
      "Model saved at checkpoints/RoadSegMulde/log_density_segmentation_checkpoint.pth\n",
      "Model saved at checkpoints/RoadSegMulde/best_log_density_segmentation_model.pth\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 3303/18150 [09:40<43:28,  5.69it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Run Training ---\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_density_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_density_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mACCUMULATION_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHECKPOINT_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBEST_MODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOAD_FROM\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 271\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(resnet, log_density_model, train_loader, val_loader, noise_levels, optimizer, scheduler, device, epochs, accumulation_steps, checkpoint_path, best_model_path, load_from)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, epochs):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 271\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_density_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_levels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validate_one_epoch(val_loader, resnet, log_density_model, noise_levels, device)\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 187\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(train_loader, resnet, log_density_model, noise_levels, optimizer, device, scaler, accumulation_steps)\u001b[0m\n\u001b[1;32m    183\u001b[0m total_patches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \n\u001b[1;32m    185\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (satellite_patches, road_maps, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m satellite_patches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m road_maps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/Projects/NeuraVisionProject/dataloaders/mass_roads_dataloader.py:82\u001b[0m, in \u001b[0;36mMassRoadsDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Read only the required image on-demand\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(sat_path) \u001b[38;5;28;01mas\u001b[39;00m sat_src:\n\u001b[0;32m---> 82\u001b[0m     sat_image \u001b[38;5;241m=\u001b[39m \u001b[43msat_src\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m  \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(map_path) \u001b[38;5;28;01mas\u001b[39;00m map_src:\n\u001b[1;32m     85\u001b[0m     map_image \u001b[38;5;241m=\u001b[39m map_src\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Run Training ---\n",
    "train_model(\n",
    "    resnet=resnet,\n",
    "    log_density_model=log_density_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    noise_levels=noise_levels,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=DEVICE,\n",
    "    epochs=EPOCHS,\n",
    "    accumulation_steps=ACCUMULATION_STEPS,\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    best_model_path=BEST_MODEL_PATH,\n",
    "    load_from=LOAD_FROM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test Evaluation ---\n",
    "def evaluate_on_test(test_loader, resnet, log_density_model, noise_levels, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test dataset.\n",
    "    \n",
    "    Args:\n",
    "        test_loader (DataLoader): Test dataset loader.\n",
    "        resnet (nn.Module): Feature extractor.\n",
    "        log_density_model (nn.Module): Road distribution model.\n",
    "        noise_levels (Tensor): Tensor of noise levels.\n",
    "        device (str): Device (cuda or cpu).\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (Average test loss, list of averaged metrics [Precision, Recall, F1, IoU])\n",
    "    \"\"\"\n",
    "    resnet.eval()\n",
    "    log_density_model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    metrics = []\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (satellite_patches, road_maps, _) in enumerate(tqdm(test_loader, desc=\"Testing\")):\n",
    "            if satellite_patches is None or road_maps is None or satellite_patches.numel() == 0:\n",
    "                # print(f\"Skipping empty batch {batch_idx+1}\")\n",
    "                continue  # Skip empty batches\n",
    "\n",
    "            satellite_patches = satellite_patches.to(device)\n",
    "            road_maps = road_maps.to(device).float().unsqueeze(1)  # Ensure correct shape\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = forward_pass(satellite_patches, noise_levels, resnet, log_density_model)\n",
    "            predictions = predictions[:, 0, :, :, :]  # Extract first noise level prediction\n",
    "\n",
    "            # Compute loss\n",
    "            loss = hybrid_loss(predictions, road_maps)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            precision, recall, f1, iou = calculate_metrics(torch.sigmoid(predictions), road_maps)\n",
    "            metrics.append([precision, recall, f1, iou])\n",
    "            num_batches += 1\n",
    "\n",
    "    # Compute average loss & metrics\n",
    "    avg_loss = test_loss / max(num_batches, 1)  # Avoid division by zero\n",
    "    avg_metrics = np.mean(metrics, axis=0) if len(metrics) > 0 else [0, 0, 0, 0]\n",
    "\n",
    "    print(f\"Test - Loss: {avg_loss:.4f} | Precision: {avg_metrics[0]:.4f} | Recall: {avg_metrics[1]:.4f} | F1: {avg_metrics[2]:.4f} | IoU: {avg_metrics[3]:.4f}\")\n",
    "    \n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "\n",
    "\n",
    "# --- Plot Predictions ---\n",
    "def plot_predictions(predictions, ground_truth, satellite_images, n_samples=5):\n",
    "    \"\"\"\n",
    "    Plots satellite images, corresponding predictions, and ground truth maps.\n",
    "\n",
    "    Args:\n",
    "        predictions (Tensor): Model-predicted road maps (B, H, W).\n",
    "        ground_truth (Tensor): Ground truth road maps (B, H, W).\n",
    "        satellite_images (Tensor): Corresponding satellite images (B, C, H, W).\n",
    "        n_samples (int): Number of samples to visualize (default: 5).\n",
    "    \"\"\"\n",
    "    n_samples = min(n_samples, len(predictions))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        pred = predictions[i].squeeze().cpu().numpy()\n",
    "        gt = ground_truth[i].squeeze().cpu().numpy()\n",
    "        sat_img = satellite_images[i].cpu().numpy().transpose(1, 2, 0)  # Convert (C, H, W) -> (H, W, C)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Satellite Image\n",
    "        axes[0].imshow(sat_img)\n",
    "        axes[0].set_title(\"Satellite Image\")\n",
    "        axes[0].axis(\"off\")\n",
    "\n",
    "        # Prediction\n",
    "        axes[1].imshow(pred, cmap=\"gray\")\n",
    "        axes[1].set_title(\"Model Prediction\")\n",
    "        axes[1].axis(\"off\")\n",
    "\n",
    "        # Ground Truth\n",
    "        axes[2].imshow(gt, cmap=\"gray\")\n",
    "        axes[2].set_title(\"Ground Truth\")\n",
    "        axes[2].axis(\"off\")\n",
    "\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluate on Test Set ---\n",
    "test_loss, test_metrics = evaluate_on_test(\n",
    "    test_loader=test_loader,\n",
    "    resnet=resnet,\n",
    "    log_density_model=log_density_model,\n",
    "    noise_levels=noise_levels,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Metrics - Precision: {test_metrics[0]:.4f}, Recall: {test_metrics[1]:.4f}, F1: {test_metrics[2]:.4f}, IoU: {test_metrics[3]:.4f}\")\n",
    "\n",
    "# --- Get a few validation samples ---\n",
    "for val_batch in val_loader:\n",
    "    if val_batch[0] is None:\n",
    "        continue  # Skip empty batches\n",
    "\n",
    "    # Unpack batch (ignore metadata)\n",
    "    sat_patches, road_maps, _ = val_batch  \n",
    "\n",
    "    # Move to device\n",
    "    sat_patches, road_maps = sat_patches.to(DEVICE), road_maps.to(DEVICE).float() / 255.0\n",
    "    road_maps = road_maps.unsqueeze(1)  # Ensure correct shape for model input\n",
    "\n",
    "    # Generate Predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = forward_pass(sat_patches, noise_levels, resnet, log_density_model)\n",
    "        predictions = predictions[:, 0, :, :, :]  # Extract first noise level prediction\n",
    "\n",
    "    # Plot the results (only 2 or 3 samples)\n",
    "    plot_predictions(predictions[:3], road_maps[:3], sat_patches[:3])\n",
    "\n",
    "    break  # Stop after visualizing the first batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
