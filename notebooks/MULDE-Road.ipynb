{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a summary of what your code is doing and a detailed table that explains how the behavior changes with different settings for the two key flags: **TRAIN_METHOD** and **RETURN_LOG_DENSITY**.\n",
    "\n",
    "---\n",
    "\n",
    "## Overview of Your Code\n",
    "\n",
    "1. **Data & Feature Extraction:**\n",
    "   - **Dataset Loading:**  \n",
    "     You load the MASS dataset (with a maximum of 2 images per split for debugging) using your custom dataloader.\n",
    "   - **Pretrained ResNet:**  \n",
    "     You extract features from images with a pretrained ResNet50 (cut off after the last convolutional layers and pooled to a 2048-dimensional vector). These features serve as the input to your subsequent log-density network.\n",
    "   - **Noise Injection:**  \n",
    "     You generate a set of noise levels (using a geometric progression between SIGMA_MIN and SIGMA_MAX). For each batch, you “repeat” the extracted features for every noise level and add scaled Gaussian noise. Then, you concatenate the noise level as an extra feature (so the network knows at which noise level it is operating).\n",
    "\n",
    "2. **Model and Loss Setup:**\n",
    "   - **Model:**  \n",
    "     You define an MLP (via the MULDE library’s `MLPs`) that takes as input the 2048-dim ResNet features plus one extra dimension (the noise level) and outputs a log-density prediction per pixel (reshaped to a WINDOW_SIZE × WINDOW_SIZE image).\n",
    "   - **Loss Branches:**\n",
    "     - **DSM (Denoising Score Matching) Loss:**  \n",
    "       For all samples with **nonzero noise** (σ ≠ 0), you compute a DSM loss. This involves comparing the network’s score prediction (the gradient of the log-density) with the scaled noise that was added.\n",
    "     - **Segmentation Loss:**  \n",
    "       For the “clean” branch (where noise level is 0), if available, you convert the log-density output (after applying a sigmoid) into segmentation predictions and compute a combined segmentation loss (a weighted sum of MSE, Binary Cross-Entropy, and Dice losses).  \n",
    "   - **Training Modes:**  \n",
    "     The overall loss is defined by the variable **TRAIN_METHOD**:\n",
    "     - In **\"Unsupervised\"** mode, only the DSM loss is used.\n",
    "     - In **\"Hybrid\"** mode, both segmentation loss and a weighted DSM loss are combined.\n",
    "     - Otherwise, the code defaults to using only the segmentation loss.\n",
    "\n",
    "3. **Gradient Handling in Validation:**\n",
    "   - In the validation loop, you wrap the overall loop in `torch.no_grad()` to disable gradient tracking. However, because the DSM loss computation requires computing gradients (via `torch.autograd.grad` inside your model’s `score()` method), you temporarily enable gradients with `torch.enable_grad()` in the DSM branch.  \n",
    "   - **Note:**  \n",
    "     While this is necessary for computing the DSM loss (which is based on gradients with respect to the input), it is somewhat unusual to compute gradients during validation. This is acceptable if you only need the loss values for evaluation and are not using them to update model weights—but it could be less efficient.\n",
    "\n",
    "4. **Live Plotting & Checkpointing:**\n",
    "   - A live plotting class updates training and validation plots in Jupyter.\n",
    "   - Checkpoints are saved whenever the validation loss improves, using helper functions for saving and loading the model and optimizer state.\n",
    "\n",
    "---\n",
    "\n",
    "## Detailed Table: Effects of TRAIN_METHOD and RETURN_LOG_DENSITY\n",
    "\n",
    "The behavior of your loss calculations and metric computations depends on two flags:\n",
    "\n",
    "- **TRAIN_METHOD:** Controls which branch of loss is used.\n",
    "- **RETURN_LOG_DENSITY:** Determines whether your model returns both the score and log-density (needed for segmentation loss).\n",
    "\n",
    "| **Configuration** | **TRAIN_METHOD** | **RETURN_LOG_DENSITY** | **DSM Loss Calculation** | **Segmentation Branch & Loss** | **Total Loss Computed** | **Metrics Computed** |\n",
    "|-------------------|------------------|------------------------|----------------------------|--------------------------------|-------------------------|----------------------|\n",
    "| **Case 1**        | Unsupervised     | True                   | Computed for all samples with σ ≠ 0 (using autograd for score) | *Not used:* Although log-density is returned, the segmentation branch is ignored in the loss calculation | **Loss = DSM loss** | Only DSM loss is used for training; segmentation metrics are not computed |\n",
    "| **Case 2**        | Unsupervised     | False                  | Computed as in Case 1 (model returns only score output) | *Not used:* No log-density is returned, so segmentation branch is not available | **Loss = DSM loss** | Only DSM loss is used; segmentation metrics are not computed |\n",
    "| **Case 3**        | Hybrid           | True                   | Computed for all samples with σ ≠ 0 | For clean samples (σ = 0): log-density is used to compute segmentation predictions (via sigmoid) and segmentation loss is calculated | **Loss = segmentation loss + DSM_WEIGHT × DSM loss** | Both DSM loss (affecting training) and segmentation metrics (precision, recall, F1, IoU) are computed |\n",
    "| **Case 4**        | Hybrid           | False                  | Computed as in Case 1 (DSM loss is computed) | *Not computed:* Since log-density is not returned, segmentation loss is zero | **Loss = DSM_WEIGHT × DSM loss** (i.e. effectively DSM loss only) | Segmentation metrics will not be available (or remain at default) since the segmentation branch is inactive |\n",
    "| **Case 5 (Default / Other)** | *Any other mode* (e.g., segmentation-only) | True/False | DSM loss is computed but may be ignored if only segmentation branch is used | If TRAIN_METHOD does not match \"Unsupervised\" or \"Hybrid\", the code falls back to using segmentation loss only (provided log-density is returned) | **Loss = segmentation loss** (if log-density is available) or 0 if not | Segmentation metrics computed if segmentation branch is active |\n",
    "\n",
    "---\n",
    "\n",
    "## Loss Calculations and Metric Details\n",
    "\n",
    "- **DSM Loss Calculation:**\n",
    "  - For samples with nonzero noise (σ ≠ 0), you compute:\n",
    "    - **Score Prediction:**  \n",
    "      Obtained via `score_pred = log_density_model.score(features_with_noise, ...)`.\n",
    "    - **Target Comparison:**  \n",
    "      Compare `score_pred[:, :-1]` (all but the last column, which is the noise level) to the scaled noise (`noise_added / (σ²)`).\n",
    "    - **Loss Term:**  \n",
    "      You compute the norm of the difference for each sample, weight it by σ² (lambda factor), and then average (normalized by batch size).\n",
    "  \n",
    "- **Segmentation Loss Calculation:**\n",
    "  - Only computed on the “clean” branch (σ == 0). If log-density is returned (i.e., RETURN_LOG_DENSITY is True):\n",
    "    - **Log-Density to Segmentation:**  \n",
    "      The log-density output is reshaped to (B, WINDOW_SIZE, WINDOW_SIZE) and passed through a sigmoid to produce segmentation probabilities.\n",
    "    - **Combined Loss:**  \n",
    "      The segmentation loss is a weighted sum of three components:\n",
    "      - **MSE Loss:** Measures pixel-wise similarity.\n",
    "      - **Binary Cross-Entropy (BCE) Loss:** Acts as a per-pixel classification loss.\n",
    "      - **Dice Loss:** Encourages overlap between prediction and target.\n",
    "      - An additional term (negative mean prediction) is added as a log-likelihood regularizer.\n",
    "  \n",
    "- **Metric Computations:**\n",
    "  - For segmentation (when available), you compute:\n",
    "    - **Precision, Recall, F1 Score, and Intersection-over-Union (IoU):**  \n",
    "      These are calculated by thresholding the segmentation predictions at 0.5 and comparing them to similarly thresholded ground truth masks using scikit-learn’s metric functions.\n",
    "  \n",
    "- **Gradient Handling in Validation:**\n",
    "  - In the validation loop, you temporarily enable gradients (using `torch.enable_grad()`) to compute DSM loss because it requires the gradient of the output with respect to the input. For the segmentation branch, the evaluation is done under `torch.no_grad()` so that gradients are not tracked there.\n",
    "\n",
    "---\n",
    "\n",
    "## Final Remarks\n",
    "\n",
    "- **Are You Wrong Somewhere?**  \n",
    "  Your overall structure is logical. One point to consider is the use of `torch.enable_grad()` in the validation loop. Although it is needed for computing the DSM loss (which requires gradients), it might be worth checking if you really need to compute DSM loss during validation or if you can disable gradient computation entirely for efficiency. In many cases, validation is done with `torch.no_grad()` unless the loss function explicitly requires gradients.\n",
    "  \n",
    "- **Choosing the Mode:**  \n",
    "  Make sure you choose the right combination of **TRAIN_METHOD** and **RETURN_LOG_DENSITY** for your experimental goals. For segmentation tasks, you’ll want **Hybrid** mode with **RETURN_LOG_DENSITY=True**. For pure DSM experiments, **Unsupervised** mode is sufficient (with either value for RETURN_LOG_DENSITY, though True may be preferred if you want to keep the interface consistent).\n",
    "\n",
    "This summary and table should help clarify the behavior of your training/validation pipeline under different configurations and ensure that your loss calculations and metrics are computed as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "while not 'dataloaders' in os.listdir():\n",
    "    os.chdir('../')\n",
    "from rasterio.errors import NotGeoreferencedWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=NotGeoreferencedWarning)\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "from dataloaders.mass_roads_dataloader import (\n",
    "    MassRoadsDataset, custom_collate_fn, get_patch_sampler\n",
    ")\n",
    "from models.MULDE.models import MLPs, ScoreOrLogDensityNetwork\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "def calculate_metrics(predictions, targets, threshold=0.5):\n",
    "    preds = (predictions > threshold).float().cpu().numpy().astype(np.uint8).flatten()\n",
    "    targets = (targets > 0.5).float().cpu().numpy().astype(np.uint8).flatten()\n",
    "    precision = precision_score(targets, preds, zero_division=1)\n",
    "    recall = recall_score(targets, preds, zero_division=1)\n",
    "    f1 = f1_score(targets, preds, zero_division=1)\n",
    "    iou = jaccard_score(targets, preds, zero_division=1)\n",
    "    return precision, recall, f1, iou\n",
    "\n",
    "def save_model(log_density_model, optimizer, epoch, loss, path):\n",
    "    directory = os.path.dirname(path)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': log_density_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, path)\n",
    "    print(f\"Model saved at {path}\")\n",
    "\n",
    "def load_checkpoint(path, log_density_model, optimizer):\n",
    "    if os.path.exists(path):\n",
    "        # Note: Check the usage of 'weights_only'. If it's not supported by torch.load, remove it.\n",
    "        checkpoint = torch.load(path, weights_only=True)\n",
    "        log_density_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        return checkpoint['epoch'], checkpoint['loss']\n",
    "    return 0, None\n",
    "\n",
    "\n",
    "DATA_DIR = '/home/ri/Desktop/Projects/Datasets/Mass_Roads/dataset/'\n",
    "CHECKPOINT_PATH = 'checkpoints/RoadSegMulde/log_density_segmentation_checkpoint.pth'\n",
    "BEST_MODEL_PATH = 'checkpoints/RoadSegMulde/best_log_density_segmentation_model.pth'\n",
    "\n",
    "WINDOW_SIZE = 128\n",
    "WINDOW_STRIDE = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SIGMA_MIN = 0.1\n",
    "SIGMA_MAX = 0.9\n",
    "NUM_NOISE_LEVELS = 31\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "LOAD_FROM = None #'last' # best or None\n",
    "# LOAD_FROM = 'last' # best or None\n",
    "\n",
    "DEBUG_LOSS_VALUES = True\n",
    "# DEBUG_LOSS_VALUES = False\n",
    "\n",
    "#################################################################################   \n",
    "# TRAIN_METHOD = \"Unsupervised\"  # or \"Unsupervised\"\n",
    "# RETURN_LOG_DENSITY = True  # Set to True to use log density score for DSM loss\n",
    "\n",
    "# TRAIN_METHOD = \"Hybrid\"  # or \"Unsupervised\"\n",
    "# RETURN_LOG_DENSITY = False # Set to False if only DSM loss is used\n",
    "\n",
    "TRAIN_METHOD = \"Unsupervised\"\n",
    "RETURN_LOG_DENSITY = True\n",
    "\n",
    "TRAIN_METHOD = \"Hybrid\"\n",
    "RETURN_LOG_DENSITY = True\n",
    "\n",
    "NUM_EPOCHS = 5 \n",
    "\n",
    "# DSM_WEIGHT = 1/((WINDOW_SIZE**4))  # weight for DSM loss in the hybrid loss\n",
    "DSM_WEIGHT = 1e-7  # Adjust to make DSM loss comparable to segmentation loss\n",
    "\n",
    "LIVE_STEPS = 5000 # Number of steps between live plots\n",
    "# LIVE_STEPS = 5  \n",
    "\n",
    "#################################################################################\n",
    "\n",
    "# arithmetic_noise = torch.linspace(SIGMA_MIN, SIGMA_MAX, steps=NUM_NOISE_LEVELS - 1).to(DEVICE)\n",
    "def generate_geometric_noise_levels(sigma_min=0.05, sigma_max=0.9, num_levels=30, device=\"cuda\"):\n",
    "    r = (sigma_min / sigma_max) ** (1 / (num_levels - 1))\n",
    "    geometric_noise_levels = sigma_max * (r ** torch.arange(num_levels, dtype=torch.float32, device=device))\n",
    "    geometric_noise_levels, _ = torch.sort(geometric_noise_levels)\n",
    "    return geometric_noise_levels\n",
    "\n",
    "noise_levels = generate_geometric_noise_levels(SIGMA_MIN, SIGMA_MAX, NUM_NOISE_LEVELS - 1)\n",
    "noise_levels = torch.cat([torch.tensor([0.0], device=DEVICE), noise_levels])\n",
    "print(\"Generated Noise Levels:\", noise_levels.cpu().numpy())\n",
    "\n",
    "# --- Dataset Preparation ---\n",
    "train_dataset = MassRoadsDataset(root_dir=DATA_DIR, split='train', window_size=WINDOW_SIZE, stride=WINDOW_STRIDE, max_images=2) # )#\n",
    "val_dataset = MassRoadsDataset(root_dir=DATA_DIR, split='valid', window_size=WINDOW_SIZE, stride=WINDOW_STRIDE, max_images=2)\n",
    "test_dataset = MassRoadsDataset(root_dir=DATA_DIR, split='test', window_size=WINDOW_SIZE, stride=WINDOW_STRIDE, max_images=2)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history, val_loss_history = [], []\n",
    "step_loss_history = []\n",
    "steps, epochs_list = [], []\n",
    "patch_count = 0  # Track total patches processed\n",
    "\n",
    "# --- Load Pretrained ResNet for Feature Extraction ---\n",
    "resnet = resnet50(pretrained=True)\n",
    "resnet = nn.Sequential(\n",
    "    *list(resnet.children())[:-2],\n",
    "    nn.AdaptiveAvgPool2d((1, 1))\n",
    ").to(DEVICE)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False  \n",
    "    param.grad = None  \n",
    "\n",
    "\n",
    "# --- Model Setup ---\n",
    "mlp = MLPs(\n",
    "    input_dim=2048 + 1,  # ResNet features + noise conditioning\n",
    "    output_dim=WINDOW_SIZE * WINDOW_SIZE,  # Pixel-wise log-density output\n",
    "    units=[4096, 4096],\n",
    "    layernorm=True,\n",
    "    dropout=0.1\n",
    ")\n",
    "log_density_model = ScoreOrLogDensityNetwork(mlp, score_network=False).to(DEVICE)\n",
    "optimizer = optim.Adam(log_density_model.parameters(), lr=1e-4, weight_decay=1e-5, betas=(0.9, 0.999))\n",
    "\n",
    "# Load checkpoint if needed\n",
    "start_epoch, best_loss = 0, float(\"inf\")\n",
    "if LOAD_FROM:\n",
    "    checkpoint_path = CHECKPOINT_PATH if LOAD_FROM == 'last' else BEST_MODEL_PATH\n",
    "    start_epoch, best_loss = load_checkpoint(checkpoint_path, log_density_model, optimizer)\n",
    "\n",
    "def add_all_noise_levels_to_features(features, noise_levels):\n",
    "    \"\"\"\n",
    "    Adds multiple noise levels to the extracted ResNet features.\n",
    "\n",
    "    Args:\n",
    "        features (torch.Tensor): Feature tensor from ResNet, shape (B, feature_dim).\n",
    "        noise_levels (torch.Tensor): 1D tensor containing predefined noise levels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Features concatenated with their corresponding noise levels, \n",
    "                      shape (B * L, feature_dim + 1).\n",
    "    \"\"\"\n",
    "    batch_size, feature_dim = features.shape\n",
    "    num_levels = len(noise_levels)\n",
    "\n",
    "    # Repeat features for each noise level\n",
    "    repeated_features = features.repeat_interleave(num_levels, dim=0)  # (B * L, feature_dim)\n",
    "\n",
    "    # Expand noise levels and concatenate\n",
    "    noise_levels_expanded = noise_levels.repeat(batch_size, 1).T.flatten().unsqueeze(1)  # (B * L, 1)\n",
    "\n",
    "    # Add noise to features\n",
    "    noisy_features = repeated_features + torch.randn_like(repeated_features) * noise_levels_expanded\n",
    "\n",
    "    # Concatenate noise level as an additional feature\n",
    "    return torch.cat([noisy_features, noise_levels_expanded], dim=1)  # (B * L, feature_dim + 1)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def live_plot(loss_history, step_history):\n",
    "    plt.clf()\n",
    "    plt.plot(step_history, loss_history, label='Training Loss')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Progress')\n",
    "    plt.legend()\n",
    "    plt.pause(0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated_log_density = -0.5 * torch.norm(score_pred[:, :-1], dim=-1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# If you want to switch between training modes, set TRAIN_METHOD to either:\n",
    "#   \"Unsupervised\"  (only DSM loss is used)\n",
    "#   \"Hybrid\"        (DSM loss + segmentation loss)\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Modify the function to return the noise that was added as well.\n",
    "# ----------------------------------------------------------------------------\n",
    "def add_all_noise_levels_to_features(features, noise_levels):\n",
    "    \"\"\"\n",
    "    Adds multiple noise levels to the extracted ResNet features and also returns the\n",
    "    added noise and the noise level for each sample.\n",
    "\n",
    "    Args:\n",
    "        features (torch.Tensor): Feature tensor from ResNet, shape (B, feature_dim).\n",
    "        noise_levels (torch.Tensor): 1D tensor containing predefined noise levels.\n",
    "\n",
    "    Returns:\n",
    "        features_with_noise_level (torch.Tensor): Tensor of shape (B * L, feature_dim + 1)\n",
    "            where the additional column contains the noise level.\n",
    "        noise (torch.Tensor): The noise that was added (shape: (B * L, feature_dim)).\n",
    "        sigma_expanded (torch.Tensor): The noise level (sigma) corresponding to each sample,\n",
    "            shape (B * L, 1).\n",
    "    \"\"\"\n",
    "    batch_size, feature_dim = features.shape\n",
    "    num_levels = len(noise_levels)\n",
    "    \n",
    "    # Repeat features for each noise level: shape (B * L, feature_dim)\n",
    "    repeated_features = features.repeat_interleave(num_levels, dim=0)\n",
    "    \n",
    "    # Expand noise levels: shape (B * L, 1)\n",
    "    sigma_expanded = noise_levels.repeat(batch_size, 1).T.flatten().unsqueeze(1)\n",
    "    \n",
    "    # Draw noise from N(0, I) and scale by sigma\n",
    "    noise = torch.randn_like(repeated_features) * sigma_expanded\n",
    "    \n",
    "    # Add noise to features\n",
    "    noisy_features = repeated_features + noise\n",
    "    \n",
    "    # Concatenate the noise level as an extra feature\n",
    "    features_with_noise_level = torch.cat([noisy_features, sigma_expanded], dim=1)\n",
    "    \n",
    "    return features_with_noise_level, noise, sigma_expanded\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Live Plot Helper (Jupyter-Compatible)\n",
    "########################################################################\n",
    "class LivePlotter:\n",
    "    def __init__(self, steps=LIVE_STEPS):\n",
    "        self.train_steps = []\n",
    "        self.train_losses = []\n",
    "        self.val_epochs = []\n",
    "        self.val_losses = []\n",
    "        self.precision_list = []\n",
    "        self.recall_list = []\n",
    "        self.f1_list = []\n",
    "        self.iou_list = []\n",
    "        self.step_count = 0\n",
    "        self.steps = steps\n",
    "        # Initialize figure\n",
    "        self.fig, self.ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    def update_train_plot(self, loss):\n",
    "        \"\"\"Update training loss plot every steps\"\"\"\n",
    "        self.step_count += 1\n",
    "        self.train_steps.append(self.step_count)\n",
    "        self.train_losses.append(loss)\n",
    "\n",
    "        if self.step_count % self.steps == 0: \n",
    "            clear_output(wait=True)  # Clear previous output\n",
    "            self.ax[0].clear()\n",
    "            self.ax[0].plot(self.train_steps, self.train_losses, label=\"Train Loss\", color=\"blue\")\n",
    "            self.ax[0].set_xlabel(\"Steps (Patches)\")\n",
    "            self.ax[0].set_ylabel(\"Loss\")\n",
    "            self.ax[0].set_title(\"Training Loss\")\n",
    "            self.ax[0].legend()\n",
    "            \n",
    "            display(self.fig)  # Show updated plot\n",
    "\n",
    "    def update_val_plot(self, val_loss=None, precision=None, recall=None, f1=None, iou=None):\n",
    "        \"\"\"Update validation loss & metrics plot even when segmentation loss is not available\"\"\"\n",
    "        self.val_epochs.append(len(self.val_epochs))\n",
    "        \n",
    "        if val_loss is not None:\n",
    "            self.val_losses.append(val_loss)\n",
    "\n",
    "        # Clear previous output for smooth updating\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # Validation loss plot\n",
    "        self.ax[1].clear()\n",
    "\n",
    "        # Only plot validation loss if it's available\n",
    "        if self.val_losses:\n",
    "            self.ax[1].plot(self.val_epochs, self.val_losses, label=\"Val Loss\", marker=\"o\", color=\"red\")\n",
    "            self.ax[1].set_xlabel(\"Epochs\")\n",
    "            self.ax[1].set_ylabel(\"Loss\")\n",
    "            self.ax[1].set_title(\"Validation Loss\")\n",
    "\n",
    "            # Remove any previous legend and add a new one\n",
    "            handles, labels = self.ax[1].get_legend_handles_labels()\n",
    "            if \"Val Loss\" in labels:  # Avoid duplicate labels\n",
    "                labels.remove(\"Val Loss\")\n",
    "                handles.pop()\n",
    "            self.ax[1].legend(handles, labels)\n",
    "\n",
    "        # Only display metrics if they exist\n",
    "        if precision is not None and recall is not None and f1 is not None and iou is not None:\n",
    "            text_str = f\"Precision: {precision:.4f}\\nRecall: {recall:.4f}\\nF1: {f1:.4f}\\nIoU: {iou:.4f}\"\n",
    "            self.ax[1].text(0.6, 0.5, text_str, transform=self.ax[1].transAxes, fontsize=12,\n",
    "                            verticalalignment='top', bbox=dict(facecolor='white', alpha=0.3))\n",
    "\n",
    "        display(self.fig)  # Show updated figure\n",
    "\n",
    "\n",
    "    def save_plots(self):\n",
    "        \"\"\"Save final plots after training\"\"\"\n",
    "        self.fig.savefig(\"training_validation_plot.png\")\n",
    "        print(\"Saved Training and Validation Loss Plots\")\n",
    "\n",
    "\n",
    "# Initialize live plotter for Jupyter Notebook\n",
    "plotter = LivePlotter()\n",
    "images, targets, _ = next(iter(train_loader))\n",
    "print(f\"Images Shape: {images.shape}, Targets Shape: {targets.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Define a helper segmentation loss function.\n",
    "# Here we mimic your earlier segmentation loss formulation\n",
    "# (MSE loss plus a term based on the negative mean prediction).\n",
    "# You can replace it with cross-entropy, Dice loss, etc.\n",
    "# ----------------------------------------------------------------------------\n",
    "# def segmentation_loss(predictions, targets):\n",
    "#     # predictions: (B, H, W), already passed through a sigmoid\n",
    "#     targets = targets.float()\n",
    "#     mse_loss = F.mse_loss(predictions, targets)\n",
    "#     log_likelihood_loss = -predictions.mean()\n",
    "#     return mse_loss + log_likelihood_loss\n",
    "\n",
    "def segmentation_loss(predictions, targets, mse_weight=0.5, bce_weight=0.3, dice_weight=0.2, smooth=1.0):\n",
    "    \"\"\"\n",
    "    Combined loss for segmentation:\n",
    "    - MSE Loss: Pixel-wise similarity.\n",
    "    - BCE Loss: Per-pixel classification.\n",
    "    - Dice Loss: Encourages better overlap with ground truth.\n",
    "    \n",
    "    Args:\n",
    "        predictions (torch.Tensor): Model output after sigmoid (B, H, W).\n",
    "        targets (torch.Tensor): Ground truth binary masks (B, H, W).\n",
    "        mse_weight (float): Weight for MSE loss.\n",
    "        bce_weight (float): Weight for BCE loss.\n",
    "        dice_weight (float): Weight for Dice loss.\n",
    "        smooth (float): Smoothing factor to avoid division by zero.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Weighted sum of MSE, BCE, and Dice losses.\n",
    "    \"\"\"\n",
    "    targets = targets.float()\n",
    "\n",
    "    # --- MSE Loss ---\n",
    "    mse_loss = F.mse_loss(predictions, targets)\n",
    "\n",
    "    # --- Binary Cross-Entropy (BCE) Loss ---\n",
    "    bce_loss = F.binary_cross_entropy(predictions, targets)\n",
    "\n",
    "    # --- Dice Loss ---\n",
    "    intersection = (predictions * targets).sum(dim=(1, 2))\n",
    "    dice_loss = 1 - (2.0 * intersection + smooth) / (predictions.sum(dim=(1, 2)) + targets.sum(dim=(1, 2)) + smooth)\n",
    "    dice_loss = dice_loss.mean()  # Average over batch\n",
    "\n",
    "    # --- Final Weighted Loss ---\n",
    "    total_loss = mse_weight * mse_loss + bce_weight * bce_loss + dice_weight * dice_loss\n",
    "\n",
    "    # Optional Log-Likelihood Regularization (Encourages uncertainty awareness)\n",
    "    log_likelihood_loss = -predictions.mean()\n",
    "    total_loss += log_likelihood_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Training loop (one epoch)\n",
    "# ----------------------------------------------------------------------------\n",
    "def train_epoch():\n",
    "    global patch_count\n",
    "    log_density_model.train()\n",
    "    running_loss = 0.0\n",
    "    patch_count = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"Training Epoch\")):\n",
    "        images, targets, _ = batch\n",
    "        if images is None:\n",
    "            continue\n",
    "        images = images.to(DEVICE)\n",
    "        targets = targets.to(DEVICE).float()\n",
    "        batch_size = images.shape[0]\n",
    "        \n",
    "        # Extract features from images using the pretrained ResNet\n",
    "        # resnet returns shape (B, feature_dim, 1, 1) so we squeeze twice.\n",
    "        features = resnet(images).squeeze(-1).squeeze(-1)  # shape: (B, 2048)\n",
    "        \n",
    "        # Add noise at all predefined levels.\n",
    "        # This returns:\n",
    "        #   - features_with_noise_level: (B * L, feature_dim+1)\n",
    "        #   - noise: the noise that was added, (B * L, feature_dim)\n",
    "        #   - sigma_expanded: the noise level per sample, (B * L, 1)\n",
    "        features_with_noise, noise_added, sigma_expanded = add_all_noise_levels_to_features(features, noise_levels)\n",
    "        # features_with_noise.requires_grad_(True)\n",
    "        features_with_noise = features_with_noise.clone().detach().requires_grad_(True)\n",
    "\n",
    "        # --- DSM (unsupervised) branch ---\n",
    "        # Call the .score() method which returns both the score prediction and log density.\n",
    "        # (The ScoreOrLogDensityNetwork is set up so that its score() method accepts a tensor\n",
    "        #  with concatenated noise-level as the last column.)\n",
    "        if RETURN_LOG_DENSITY:\n",
    "            score_pred, log_density_pred = log_density_model.score(features_with_noise, return_log_density=True)\n",
    "        else:\n",
    "            score_pred = log_density_model.score(features_with_noise, return_log_density=False)\n",
    "            log_density_pred = None\n",
    "        \n",
    "        # Compute DSM loss only for nonzero noise levels (avoid division by zero)\n",
    "        nonzero_mask = (sigma_expanded != 0).squeeze()  # Boolean mask\n",
    "        \n",
    "        nonzero_mask = (sigma_expanded != 0).squeeze()\n",
    "        loss_dsm = torch.tensor(0.0, device=DEVICE)\n",
    "        if nonzero_mask.sum() > 0:\n",
    "            score_nonzero = score_pred[nonzero_mask]\n",
    "            noise_nonzero = noise_added[nonzero_mask]\n",
    "            sigma_nonzero = sigma_expanded[nonzero_mask]\n",
    "            lambda_factor = sigma_nonzero ** 2\n",
    "            # Exclude the last dimension (which holds the noise-level)\n",
    "            # and compare with the scaled noise.\n",
    "            dsm_term = torch.norm(score_nonzero[:, :-1] + noise_nonzero / (sigma_nonzero ** 2), dim=-1) ** 2\n",
    "            loss_dsm = (lambda_factor * dsm_term).sum() / batch_size  # Normalize by patches\n",
    "\n",
    "        \n",
    "        # --- Segmentation branch ---\n",
    "        # Use only the \"clean\" branch (where sigma == 0) to obtain segmentation predictions.\n",
    "        loss_seg = torch.tensor(0.0, device=DEVICE)\n",
    "        if RETURN_LOG_DENSITY and log_density_pred is not None:\n",
    "            clean_mask = (sigma_expanded == 0).squeeze()\n",
    "            if clean_mask.sum() > 0:\n",
    "                clean_log_density = log_density_pred[clean_mask]  # shape: (B, WINDOW_SIZE*WINDOW_SIZE)\n",
    "                # Reshape to (B, WINDOW_SIZE, WINDOW_SIZE) and apply sigmoid to get probabilities.\n",
    "                seg_pred = torch.sigmoid(clean_log_density).view(-1, WINDOW_SIZE, WINDOW_SIZE)\n",
    "                loss_seg = segmentation_loss(seg_pred, targets)\n",
    "        \n",
    "        # --- Combine losses based on the chosen training mode ---\n",
    "        if TRAIN_METHOD == \"Unsupervised\":\n",
    "            loss = loss_dsm\n",
    "        elif TRAIN_METHOD == \"Hybrid\":\n",
    "            loss = loss_seg + DSM_WEIGHT * loss_dsm\n",
    "        else:\n",
    "            # Default to segmentation only if no valid training mode is selected.\n",
    "            loss = loss_seg\n",
    "        \n",
    "        if DEBUG_LOSS_VALUES and (batch_idx + 1) % LIVE_STEPS == 0:\n",
    "            print(f\"Training  - Loss DSM: {loss_dsm.item()} , Weighted: {DSM_WEIGHT * loss_dsm}, Loss Seg: {loss_seg.item()}, Loss Total: {loss.item()}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_size\n",
    "        patch_count += batch_size\n",
    "\n",
    "        plotter.update_train_plot(loss.item()) # Update the training plot with the current loss value\n",
    "    \n",
    "    avg_loss = running_loss / patch_count\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Validation loop (one epoch)\n",
    "# For hybrid training, we also compute segmentation metrics.\n",
    "# ----------------------------------------------------------------------------\n",
    "def validate_epoch():\n",
    "    log_density_model.eval()\n",
    "    total_loss = 0.0\n",
    "    patch_count = 0\n",
    "    seg_preds_list = []\n",
    "    seg_targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(val_loader, desc=\"Validation Epoch\")):\n",
    "            images, targets, _ = batch\n",
    "            if images is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(DEVICE)\n",
    "            targets = targets.to(DEVICE).float()\n",
    "            batch_size = images.shape[0]\n",
    "        \n",
    "            features = resnet(images).squeeze(-1).squeeze(-1)\n",
    "\n",
    "             # Remove `torch.no_grad()` inside the loop for DSM loss computation\n",
    "            with torch.enable_grad():  # Enable gradient computation for DSM loss\n",
    "                features_with_noise, noise_added, sigma_expanded = add_all_noise_levels_to_features(features, noise_levels)\n",
    "                features_with_noise.requires_grad_(True)  # Ensure gradients are tracked\n",
    "\n",
    "                if RETURN_LOG_DENSITY:\n",
    "                    score_pred, log_density_pred = log_density_model.score(features_with_noise, return_log_density=True)\n",
    "                else:\n",
    "                    score_pred = log_density_model.score(features_with_noise, return_log_density=False)\n",
    "                    log_density_pred = None\n",
    "\n",
    "                \n",
    "                # Compute DSM loss\n",
    "                nonzero_mask = (sigma_expanded != 0).squeeze()\n",
    "                loss_dsm = torch.tensor(0.0, device=DEVICE)\n",
    "                if nonzero_mask.sum() > 0:\n",
    "                    score_nonzero = score_pred[nonzero_mask]\n",
    "                    noise_nonzero = noise_added[nonzero_mask]\n",
    "                    sigma_nonzero = sigma_expanded[nonzero_mask]\n",
    "                    lambda_factor = sigma_nonzero ** 2\n",
    "                    dsm_term = torch.norm(score_nonzero[:, :-1] + noise_nonzero / (sigma_nonzero ** 2), dim=-1) ** 2\n",
    "                    loss_dsm = (lambda_factor * dsm_term).sum() / batch_size  # Normalize by patches\n",
    "\n",
    "            loss_seg = torch.tensor(0.0, device=DEVICE)\n",
    "            precision, recall, f1, iou = None, None, None, None\n",
    "            # Re-enable `torch.no_grad()` for segmentation loss evaluation\n",
    "            with torch.no_grad():\n",
    "                loss_seg = torch.tensor(0.0, device=DEVICE)\n",
    "                if RETURN_LOG_DENSITY and log_density_pred is not None:\n",
    "                    clean_mask = (sigma_expanded == 0).squeeze()\n",
    "                    if clean_mask.sum() > 0:\n",
    "                        clean_log_density = log_density_pred[clean_mask]\n",
    "                        seg_pred = torch.sigmoid(clean_log_density).view(-1, WINDOW_SIZE, WINDOW_SIZE)\n",
    "                        loss_seg = segmentation_loss(seg_pred, targets)\n",
    "                        seg_preds_list.append(seg_pred)\n",
    "                        seg_targets_list.append(targets)\n",
    "                        \n",
    "                clean_mask = (sigma_expanded == 0).squeeze()\n",
    "                loss_seg = torch.tensor(0.0, device=DEVICE)\n",
    "                \n",
    "                    \n",
    "                if TRAIN_METHOD == \"Unsupervised\":\n",
    "                    loss = loss_dsm\n",
    "                elif TRAIN_METHOD == \"Hybrid\":\n",
    "                    loss = loss_seg + DSM_WEIGHT * loss_dsm\n",
    "                else:\n",
    "                    loss = loss_seg\n",
    "                \n",
    "                total_loss += loss.item() * batch_size\n",
    "                patch_count += batch_size\n",
    "\n",
    "            avg_val_loss = total_loss / patch_count  # Normalize by patches\n",
    "\n",
    "            if TRAIN_METHOD == \"Unsupervised\":\n",
    "                loss = loss_dsm\n",
    "            elif TRAIN_METHOD == \"Hybrid\":\n",
    "                loss = loss_seg + DSM_WEIGHT * loss_dsm\n",
    "            else:\n",
    "                loss = loss_seg\n",
    "            \n",
    "            if DEBUG_LOSS_VALUES and (batch_idx + 1) % LIVE_STEPS == 0:\n",
    "                print(f\"Validation  - Loss DSM: {loss_dsm.item()} , Weighted: {DSM_WEIGHT * loss_dsm}, Loss Seg: {loss_seg.item()}, Loss Total: {loss.item()}\")       \n",
    "            total_loss += loss.item() * batch_size\n",
    "            patch_count += batch_size\n",
    "            \n",
    "    \n",
    "    avg_val_loss = total_loss / patch_count # Normalize by patches\n",
    "\n",
    "    \n",
    "    if TRAIN_METHOD == \"Hybrid\" and seg_preds_list:\n",
    "        seg_preds_all = torch.cat(seg_preds_list, dim=0)\n",
    "        seg_targets_all = torch.cat(seg_targets_list, dim=0)\n",
    "        precision, recall, f1, iou = calculate_metrics(seg_preds_all, seg_targets_all)\n",
    "        print(f\"Validation Segmentation Metrics - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, IoU: {iou:.4f}\")\n",
    "        plotter.update_val_plot(avg_val_loss, precision, recall, f1, iou)\n",
    "    \n",
    "    if RETURN_LOG_DENSITY and seg_preds_list:\n",
    "        seg_preds_all = torch.cat(seg_preds_list, dim=0)\n",
    "        seg_targets_all = torch.cat(seg_targets_list, dim=0)\n",
    "        precision, recall, f1, iou = calculate_metrics(seg_preds_all, seg_targets_all)\n",
    "\n",
    "    plotter.update_val_plot(avg_val_loss, precision, recall, f1, iou)\n",
    "\n",
    "    return avg_val_loss\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Main training loop\n",
    "# ----------------------------------------------------------------------------\n",
    "best_val_loss = float(\"inf\")\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    train_loss = train_epoch()\n",
    "    val_loss = validate_epoch()\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]  Train Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Save the model if the validation loss improved.\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(f\"Saving best model at epoch {epoch+1} with val loss {val_loss:.4f}\")\n",
    "        save_model(log_density_model, optimizer, epoch, val_loss, BEST_MODEL_PATH)\n",
    "\n",
    "    save_model(log_density_model, optimizer, epoch, val_loss, CHECKPOINT_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28198060.0 / 128 /128 / 32 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def plot_zero_noise_predictions(\n",
    "    model,         # ScoreOrLogDensityNetwork\n",
    "    feature_net,   # e.g., ResNet feature extractor\n",
    "    loader,        # A DataLoader (train_loader, val_loader or test_loader)\n",
    "    device, \n",
    "    window_size=128,\n",
    "    n_samples=3\n",
    "):\n",
    "    \"\"\"\n",
    "    Show n_samples predictions at zero noise level along with the patch & ground truth.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()                # Switch to eval mode\n",
    "    feature_net.eval()          # Typically kept in eval mode too\n",
    "\n",
    "    # Grab one batch of data\n",
    "    images, targets, _ = next(iter(loader))\n",
    "\n",
    "    # Move to device\n",
    "    images, targets = images.to(device), targets.to(device)\n",
    "    \n",
    "    # Extract features via the pretrained ResNet (or any feature net)\n",
    "    with torch.no_grad():\n",
    "        feats = feature_net(images).squeeze(-1).squeeze(-1)  # (B, 2048) for ResNet-50\n",
    "\n",
    "    # Construct input for zero-noise level:\n",
    "    #   concatenating feats with a 0-column for noise level\n",
    "    #   shape -> (B, 2048 + 1)\n",
    "    zero_noise = torch.zeros(feats.size(0), 1, device=device)\n",
    "    feats_zero_noise = torch.cat([feats, zero_noise], dim=1)\n",
    "\n",
    "    # Forward pass through the ScoreOrLogDensityNetwork\n",
    "    # with torch.no_grad():\n",
    "    # If your network returns (score, log_density) when return_log_density=True:\n",
    "    _, log_density_pred = model.score(feats_zero_noise, return_log_density=True)\n",
    "    # Reshape to (B, H, W), apply sigmoid to get probabilities\n",
    "    seg_pred = torch.sigmoid(log_density_pred).view(-1, window_size, window_size)\n",
    "\n",
    "    # Plot up to n_samples results\n",
    "    for i in range(min(n_samples, images.size(0))):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "        # Show the patch (RGB)\n",
    "        axes[0].imshow(images[i].permute(1, 2, 0).cpu().numpy())\n",
    "        axes[0].set_title(\"Image Patch\")\n",
    "        axes[0].axis(\"off\")\n",
    "\n",
    "        # Show predicted mask (grayscale)\n",
    "        axes[1].imshow(seg_pred[i].cpu().detach().numpy(), cmap=\"gray\")\n",
    "        axes[1].set_title(\"Prediction (σ=0)\")\n",
    "        axes[1].axis(\"off\")\n",
    "\n",
    "        # Show ground truth (grayscale)\n",
    "        axes[2].imshow(targets[i].cpu().numpy(), cmap=\"gray\")\n",
    "        axes[2].set_title(\"Ground Truth\")\n",
    "        axes[2].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "############################################\n",
    "# Example usage in your training script:\n",
    "############################################\n",
    "\n",
    "# ...\n",
    "# Assume you already have:\n",
    "#   log_density_model        # ScoreOrLogDensityNetwork\n",
    "#   resnet                  # feature_net, e.g. ResNet-50\n",
    "#   test_loader             # or val_loader\n",
    "#   DEVICE\n",
    "\n",
    "plot_zero_noise_predictions(\n",
    "    model=log_density_model,\n",
    "    feature_net=resnet,\n",
    "    loader=val_loader,#test_loader,      # or val_loader\n",
    "    device=DEVICE,\n",
    "    window_size=128,\n",
    "    n_samples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ----------------------------------------------------------------------------\n",
    "# # Optionally, define a test function to evaluate the model on the test set.\n",
    "# # ----------------------------------------------------------------------------\n",
    "# def test_model():\n",
    "#     log_density_model.eval()\n",
    "#     seg_preds_list = []\n",
    "#     seg_targets_list = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "#             images, targets, _ = batch\n",
    "#             images = images.to(DEVICE)\n",
    "#             targets = targets.to(DEVICE).float()\n",
    "#             if images is None:\n",
    "#                 continue\n",
    "#             features = resnet(images).squeeze(-1).squeeze(-1)\n",
    "#             features_with_noise, noise_added, sigma_expanded = add_all_noise_levels_to_features(features, noise_levels)\n",
    "\n",
    "#             score_pred, log_density_pred = log_density_model.score(features_with_noise, return_log_density=RETURN_LOG_DENSITY)\n",
    "            \n",
    "#             clean_mask = (sigma_expanded == 0).squeeze()\n",
    "#             if clean_mask.sum() > 0:\n",
    "#                 clean_log_density = log_density_pred[clean_mask]\n",
    "#                 seg_pred = torch.sigmoid(clean_log_density).view(-1, WINDOW_SIZE, WINDOW_SIZE)\n",
    "#                 seg_preds_list.append(seg_pred)\n",
    "#                 seg_targets_list.append(targets)\n",
    "    \n",
    "#     if seg_preds_list:\n",
    "#         seg_preds_all = torch.cat(seg_preds_list, dim=0)\n",
    "#         seg_targets_all = torch.cat(seg_targets_list, dim=0)\n",
    "#         precision, recall, f1, iou = calculate_metrics(seg_preds_all, seg_targets_all)\n",
    "#         print(f\"Test Metrics - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, IoU: {iou:.4f}\")\n",
    "\n",
    "# # Run testing after training\n",
    "# test_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_prediction(image, prediction, ground_truth):\n",
    "    \"\"\"Plots the original image, predicted segmentation mask, and ground truth.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].imshow(image.permute(1, 2, 0).cpu().numpy())  # Original image\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    \n",
    "    axes[1].imshow(prediction.cpu().numpy(), cmap=\"gray\")  # Predicted segmentation mask\n",
    "    axes[1].set_title(\"Predicted Mask\")\n",
    "    \n",
    "    axes[2].imshow(ground_truth.cpu().numpy(), cmap=\"gray\")  # Ground truth mask\n",
    "    axes[2].set_title(\"Ground Truth\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patches_and_distribution_with_counts(sat_patches, map_patches, metadata, n_patches=3):\n",
    "    \"\"\"\n",
    "    Efficiently plots randomly selected satellite patches, road masks, and road pixel distributions.\n",
    "    \n",
    "    Args:\n",
    "        sat_patches (Tensor): Batch of satellite image patches.\n",
    "        map_patches (Tensor): Batch of road mask patches.\n",
    "        metadata (List[Tuple[int, int, int]]): Metadata with (image_idx, y, x).\n",
    "        n_patches (int): Number of patches to visualize.\n",
    "    \"\"\"\n",
    "    n_patches = min(n_patches, sat_patches.shape[0])  # Ensure we do not exceed available patches\n",
    "\n",
    "    # Randomly select `n_patches` indices from the batch\n",
    "    selected_indices = random.sample(range(sat_patches.shape[0]), n_patches)\n",
    "\n",
    "    fig, axes = plt.subplots(n_patches, 3, figsize=(15, 5 * n_patches))\n",
    "\n",
    "    # Ensure axes is always iterable\n",
    "    if n_patches == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        sat_patch = sat_patches[idx]\n",
    "        map_patch = map_patches[idx]\n",
    "\n",
    "        # Convert tensors to numpy\n",
    "        if isinstance(sat_patch, torch.Tensor):\n",
    "            sat_patch = sat_patch.cpu().numpy().transpose(1, 2, 0)  # Convert to HxWxC\n",
    "        if isinstance(map_patch, torch.Tensor):\n",
    "            map_patch = map_patch.cpu().numpy()\n",
    "\n",
    "        # Extract metadata (fix KeyError)\n",
    "        image_idx, y, x = metadata[idx]  \n",
    "\n",
    "        # Plot Satellite Patch\n",
    "        axes[i][0].imshow(sat_patch)\n",
    "        axes[i][0].set_title(f\"Satellite Patch {i+1}\\nImage Index: {image_idx}, Coords: ({y}, {x})\")\n",
    "        axes[i][0].axis('off')\n",
    "\n",
    "        # Plot Map Patch\n",
    "        axes[i][1].imshow(map_patch, cmap='gray')\n",
    "        axes[i][1].set_title(f\"Map Patch {i+1}\")\n",
    "        axes[i][1].axis('off')\n",
    "\n",
    "        # Plot Distribution of Road Pixels\n",
    "        road_pixel_count = np.sum(map_patch)\n",
    "        non_road_pixel_count = map_patch.size - road_pixel_count\n",
    "        labels = ['Non-Road', 'Road']\n",
    "        sizes = [non_road_pixel_count, road_pixel_count]\n",
    "\n",
    "        axes[i][2].pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=['gray', 'blue'])\n",
    "        axes[i][2].set_title(f\"Road Pixel Distribution (Patch {i+1})\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Count total batches in the dataset\n",
    "total_batches = len(train_loader)\n",
    "\n",
    "print(f\"Total Batches in Dataset: {total_batches}\\n\")\n",
    "\n",
    "# Iterate through the DataLoader and print batch sizes\n",
    "for batch_idx, (sat_patches, map_patches, metadata) in enumerate(train_loader):\n",
    "    if sat_patches is None or map_patches is None:\n",
    "        print(f\"Batch {batch_idx+1}: Skipped (Empty Batch)\")\n",
    "        continue  # Skip empty batches\n",
    "\n",
    "    # Print batch info\n",
    "    print(f\"\\nBatch {batch_idx+1}/{total_batches}:\")\n",
    "    print(f\"  Requested Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"  Actual Batch Size: {sat_patches.shape[0]}\")  # The number of patches in this batch\n",
    "    print(f\"  Patch Shape: {sat_patches.shape}\")  # (batch_size, channels, height, width)\n",
    "\n",
    "    if batch_idx >= 3:  # Stop printing after a few batches to avoid excessive output\n",
    "        break\n",
    "\n",
    "\n",
    "# --- Efficiently Load ONE Batch ---\n",
    "try:\n",
    "    batch = next(iter(train_loader))  # Load one batch\n",
    "    sat_patches, map_patches, metadata = batch\n",
    "\n",
    "    if sat_patches is not None and len(sat_patches) > 0:\n",
    "        plot_patches_and_distribution_with_counts(sat_patches, map_patches, metadata, n_patches=3)  # Show 3 patches\n",
    "    else:\n",
    "        print(\"No valid patches found in the batch.\")\n",
    "\n",
    "except StopIteration:\n",
    "    print(\"No data available in train_loader.\")\n",
    "\n",
    "\n",
    "noise_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scenario: Learning the Distribution of Roads**\n",
    "You are **learning the distribution of roads** when you use **DSM loss** to train the MULDE model. This occurs when:\n",
    "\n",
    "1. **TRAIN_METHOD = \"Unsupervised\"**  \n",
    "   - Only the DSM loss is used.  \n",
    "   - The model is trained to approximate the **score function** (i.e., the gradient of the log-density of road features).  \n",
    "   - No segmentation labels are used in training.  \n",
    "\n",
    "2. **TRAIN_METHOD = \"Hybrid\"** (Partial Distribution Learning)  \n",
    "   - DSM loss is still computed, but segmentation loss is also included.  \n",
    "   - The model learns **both** the distribution of road pixels **and** a direct segmentation mapping.\n",
    "\n",
    "3. **RETURN_LOG_DENSITY = True**  \n",
    "   - The model is explicitly predicting log-density values.  \n",
    "   - The log-density represents how likely a feature (from ResNet) belongs to the distribution of road pixels.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Why DSM Loss Helps in Learning the Distribution**\n",
    "- DSM loss trains the model to estimate **score functions** of the log-probability density function (log-pdf) of the road dataset.\n",
    "- When the model learns to approximate **score(x) ≈ ∇ log p(x)**, it effectively captures the probability density of roads.\n",
    "- This means the model **learns the underlying data distribution** rather than a direct classification of pixels.\n",
    "\n",
    "---\n",
    "\n",
    "### **Table: When Are You Learning the Road Distribution?**\n",
    "| **Scenario**                        | **TRAIN_METHOD** | **RETURN_LOG_DENSITY** | **Are You Learning the Road Distribution?** | **Explanation** |\n",
    "|--------------------------------------|------------------|------------------------|----------------------------------------------|----------------|\n",
    "| **Case 1: Pure Distribution Learning** | `\"Unsupervised\"` | `True`                 | ✅ **Yes (Best Setting)** | The model learns the DSM loss and predicts log-density values. This directly models the road distribution. |\n",
    "| **Case 2: Distribution Learning + Segmentation** | `\"Hybrid\"`       | `True`                 | ✅ **Partial** | The model learns both the distribution and segmentation. DSM loss still captures road distribution. |\n",
    "| **Case 3: Learning Score Function (But No Log-Density Output)** | `\"Unsupervised\"` | `False`                | ✅ **Yes, but Indirectly** | The model still learns DSM loss, but log-density is not explicitly predicted. You can approximate it using score norms. |\n",
    "| **Case 4: Hybrid Without Log-Density Output** | `\"Hybrid\"`       | `False`                | ❌ **Not Fully** | The DSM loss still affects training, but without log-density output, the model is biased more toward segmentation. |\n",
    "| **Case 5: Pure Segmentation** | `\"Other\"` (Segmentation only) | `True` or `False` | ❌ **No** | The model does not learn the road distribution, only pixel classification. |\n",
    "\n",
    "---\n",
    "\n",
    "### **Best Setting for Learning Road Distribution**\n",
    "🔹 **Use:**  \n",
    "```python\n",
    "TRAIN_METHOD = \"Unsupervised\"\n",
    "RETURN_LOG_DENSITY = True\n",
    "```\n",
    "🔹 **Effect:**  \n",
    "- The model learns the probability distribution of road features.\n",
    "- No segmentation labels are used.\n",
    "- The output log-density can be used for **road anomaly detection**, density estimation, or further probabilistic modeling.\n",
    "\n",
    "If you also want segmentation while still learning the road distribution, use:\n",
    "```python\n",
    "TRAIN_METHOD = \"Hybrid\"\n",
    "RETURN_LOG_DENSITY = True\n",
    "```\n",
    "This will ensure that DSM loss is present, **but segmentation loss is also included**.\n",
    "\n",
    " **If your primary goal is to learn the road distribution, stick to `Unsupervised` mode with `RETURN_LOG_DENSITY=True`.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
